
# Multimodal Representation Learning

## Methods

- Kevin Murphy (2023) "Probabilistic Machine Learning: Advanced Topics" ["Probabilistic Machine Learning: Advanced Topics" ](https://probml.github.io/pml-book/book2.html)- Chapter 32 - Representation Learning.
- Wu, H., Mao, J., Zhang, Y., Jiang, Y., Li, L., Sun, W., & Ma, W. Y. (2019). ["Unified visual-semantic embeddings: Bridging vision and language with structured meaning representations"](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Unified_Visual-Semantic_Embeddings_Bridging_Vision_and_Language_With_Structured_Meaning_CVPR_2019_paper.pdf). In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6609-6618).
- Lu, J., Batra, D., Parikh, D., & Lee, S. (2019). ["Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks"](https://proceedings.neurips.cc/paper/2019/file/c74d97b01eae257e44aa9d5bade97baf-Paper.pdf). Advances in neural information processing systems, 32.
- Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021, July). ["Learning transferable visual models from natural language supervision"](http://proceedings.mlr.press/v139/radford21a/radford21a.pdf). In International conference on machine learning (pp. 8748-8763). PMLR.
- Shi, Y., Paige, B., & Torr, P. (2019). ["Variational mixture-of-experts autoencoders for multi-modal deep generative models"](https://proceedings.neurips.cc/paper/2019/file/0ae775a8cb3b499ad1fca944e6f5c836-Paper.pdf). Advances in Neural Information Processing Systems, 32.

## Applications

- Dew, Ryan, Asim Ansari, and Olivier Toubia. ["Letting logos speak: Leveraging multiview representation learning for data-driven branding and logo design."](https://pubsonline.informs.org/doi/abs/10.1287/mksc.2021.1326) Marketing Science 41.2 (2022): 401-425.
- Tian, Zijun and Dew, Ryan and Iyengar, Raghuram. ["Mega or Micro? Influencer Selection Using Follower Elasticity"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4173421). **Working Paper**. Available at SSRN: https://ssrn.com/abstract=4173421 or http://dx.doi.org/10.2139/ssrn.4173421
- Burnap, Alex, John R. Hauser, and Artem Timoshenko. ["Product aesthetic design: A machine learning augmentation."](https://pubsonline.informs.org/doi/full/10.1287/mksc.2022.1429). **Forthcoming**. Marketing Science (2023).
- Davide Costa, Lucio La Cava, and Andrea Tagarelli. 2023. ["Show me your NFT and I tell you how it will perform: Multimodal representation learning for NFT selling price prediction"](https://arxiv.org/abs/2302.01676). In Proceedings of the ACM Web Conference 2023 (WWW '23). Association for Computing Machinery, New York, NY, USA, 1875–1885. https://doi.org/10.1145/3543507.3583520
- Cheng, Zhaoqi and Lee, Dokyun and Tambe, Prasanna. ["InnoVAE: Generative AI for Understanding Patents and Innovation"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3868599). **Working Paper**. Available at SSRN: https://ssrn.com/abstract=3868599 or http://dx.doi.org/10.2139/ssrn.3868599

# Dynamic Embeddings

## Methods
- Kutuzov, A., Øvrelid, L., Szymanski, T., & Velldal, E. (2018). ["Diachronic word embeddings and semantic shifts: a survey"](https://arxiv.org/pdf/1806.03537.pdf). arXiv preprint arXiv:1806.03537.
- Rudolph, M., & Blei, D. (2018, April). ["Dynamic embeddings for language evolution"](https://dl.acm.org/doi/pdf/10.1145/3178876.3185999). In Proceedings of the 2018 world wide web conference (pp. 1003-1011).
- Bamler, R., & Mandt, S. (2017, July). ["Dynamic word embeddings"](http://proceedings.mlr.press/v70/bamler17a/bamler17a.pdf). In International conference on Machine learning (pp. 380-389). PMLR.
- Dieng, A. B., Ruiz, F. J., & Blei, D. M. (2019). ["The dynamic embedded topic model"](https://arxiv.org/pdf/1907.05545.pdf). arXiv preprint arXiv:1907.05545.
- Giulianelli, M., Del Tredici, M., & Fernández, R. (2020). ["Analysing lexical semantic change with contextualised word representations"](https://arxiv.org/pdf/2004.14118.pdf). arXiv preprint arXiv:2004.14118.
- Dhingra, B., Cole, J. R., Eisenschlos, J. M., Gillick, D., Eisenstein, J., & Cohen, W. W. (2022). ["Time-aware language models as temporal knowledge bases"](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00459/110012/Time-Aware-Language-Models-as-Temporal-Knowledge). Transactions of the Association for Computational Linguistics, 10, 257-273.

## Applications
- Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). ["Word embeddings quantify 100 years of gender and ethnic stereotypes"](https://www.pnas.org/doi/full/10.1073/pnas.1720347115). Proceedings of the National Academy of Sciences, 115(16), E3635-E3644.
- Soni, S., Lerman, K., & Eisenstein, J. (2021). ["Follow the leader: Documents on the leading edge of semantic change get more citations"](https://asistdl.onlinelibrary.wiley.com/doi/am-pdf/10.1002/asi.24421). Journal of the Association for Information Science and Technology, 72(4), 478-492.
- Lucy, L., & Bamman, D. (2021). ["Characterizing English variation across social media communities with BERT"](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00383/101877). Transactions of the Association for Computational Linguistics, 9, 538-556.
- Hofmarcher, P., Adhikari, S., & Grün, B. (2022). ["Gaining Insights on US Senate Speeches Using a Time Varying Text Based Ideal Point Model"](https://arxiv.org/pdf/2206.10877.pdf). arXiv preprint arXiv:2206.10877.
